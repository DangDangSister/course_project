{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.preprocessing import scale\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.models import load_model\n",
    "from keras import metrics\n",
    "from keras.regularizers import l2\n",
    "import models.nnmodels as nn\n",
    "import utils.data as data\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DEAP dataset...\n",
      "DEAP dataset is loaded.\n",
      "\n",
      "##### Dataset representation for each subject #####\n",
      "\n",
      "There are 32 subjects in the dataset.\n",
      "\n",
      "(Trail/Video, Channel, Readings) :  (40, 40, 8064)\n",
      "(Trail/Video, label (valence or arousal)) :  (40, 2)\n"
     ]
    }
   ],
   "source": [
    "print 'Loading DEAP dataset...'\n",
    "subject_data_folds, valence_folds, arousal_folds = data.load_deap(32, 2)\n",
    "print 'DEAP dataset is loaded.\\n'\n",
    "\n",
    "print 5*'#' + ' Dataset representation for each subject ' + 5*'#'\n",
    "print '\\nThere are {} subjects in the dataset.\\n'.format(len(subject_data_folds))\n",
    "print '(Trail/Video, Channel, Readings) : ', subject_data_folds[0].shape\n",
    "print '(Trail/Video, label (valence or arousal)) : ', arousal_folds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(arousal_folds[1]==arousal_folds[1])/(2*len(arousal_folds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 4030)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select last 30 seconds of only EGG channels\n",
    "subject_egg_data_folds = []\n",
    "for s in subject_data_folds:\n",
    "    subject_egg_data_folds.append(s[:,:,4032:-2])\n",
    "    \n",
    "# Check the shape\n",
    "subject_egg_data_folds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 15, 4030)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean mask to select specific channels\n",
    "# mask to select channels 1, 2, 4, 5, 8, 10, 15, 21, 22, 25, 26, 27, 28, 31, 32\n",
    "mask = [True, True, False, True, True, False, False, True, False, True, False, False, False, False, True, \\\n",
    "       False, False, False, False, False, True, True, False, False, True, True, True, True, False, False, \\\n",
    "       True, True, False, False, False, False, False, False, False, False]\n",
    "\n",
    "subject_selected_egg_folds = []\n",
    "for s in subject_egg_data_folds:\n",
    "    subject_selected_egg_folds.append(s[:,mask,:])\n",
    "\n",
    "# Check the shape\n",
    "subject_selected_egg_folds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 15, 4030)\n",
      "(1280, 60450)\n",
      "(1280, 15, 4030)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Split each sample into 10 sample (400 experiment per subject) \\nfrom sklearn.preprocessing import scale\\nX = np.concatenate(subject_egg_data_folds, axis=0)\\nprint  X.shape\\nX_reshaped=X.reshape(X.shape[0], X.shape[1]*X.shape[2])\\nprint X_reshaped.shape\\nX_reshaped_norm = scale(X_reshaped)\\nX_norm = X_reshaped_norm.reshape(X.shape[0], X.shape[1],X.shape[2])\\nprint  X_norm.shape\\nmy_egg_data = []\\nfor egg_fold in subject_egg_data_folds:\\n    \\n    subject_splited = np.split(egg_fold, 10, axis=-1)\\n    augmented_subject = np.concatenate(subject_splited)\\n    \\n    my_egg_data.append(augmented_subject)\\n    '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split each sample into 10 sample (400 experiment per subject) \n",
    "\n",
    "X = np.concatenate(subject_selected_egg_folds, axis=0)\n",
    "print  X.shape\n",
    "X_reshaped=X.reshape(X.shape[0], X.shape[1]*X.shape[2])\n",
    "print X_reshaped.shape\n",
    "X_reshaped_norm = scale(X_reshaped)\n",
    "X_norm = X_reshaped_norm.reshape(X.shape[0], X.shape[1],X.shape[2])\n",
    "print  X_norm.shape\n",
    "my_egg_data = []\n",
    "for egg_fold in subject_selected_egg_folds:\n",
    "    \n",
    "    subject_splited = np.split(egg_fold, 10, axis=-1)\n",
    "    augmented_subject = np.concatenate(subject_splited)\n",
    "    \n",
    "    my_egg_data.append(augmented_subject)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Split each sample into 10 sample (400 experiment per subject) \n",
    "from sklearn.preprocessing import scale\n",
    "X = np.concatenate(subject_egg_data_folds, axis=0)\n",
    "print  X.shape\n",
    "X_reshaped=X.reshape(X.shape[0], X.shape[1]*X.shape[2])\n",
    "print X_reshaped.shape\n",
    "X_reshaped_norm = scale(X_reshaped)\n",
    "X_norm = X_reshaped_norm.reshape(X.shape[0], X.shape[1],X.shape[2])\n",
    "print  X_norm.shape\n",
    "my_egg_data = []\n",
    "for egg_fold in subject_egg_data_folds:\n",
    "    \n",
    "    subject_splited = np.split(egg_fold, 10, axis=-1)\n",
    "    augmented_subject = np.concatenate(subject_splited)\n",
    "    \n",
    "    my_egg_data.append(augmented_subject)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the labels for experiments\n",
    "\n",
    "new_valence_folds = []\n",
    "for l in valence_folds:\n",
    "    new_l = l.repeat(10, axis=0)\n",
    "    new_valence_folds.append(new_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 15, 403)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_egg_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import periodogram\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def psd(data):\n",
    "    \n",
    "    \n",
    "        def summerize(sub_band):\n",
    "            \n",
    "            exp, ch, r = sub_band.shape\n",
    "            \n",
    "            sub_band_summerized = np.sum(np.square(sub_band), axis=-1, keepdims=True)\n",
    "            \"\"\"\n",
    "            # Mean of the sub band\n",
    "            sub_band_summerized = sub_band.mean(axis=-1, keepdims=True)\n",
    "            \n",
    "            # Median of the sub band\n",
    "            sub_band_summerized = np.append(sub_band_summerized, np.median(sub_band, axis=-1, keepdims=True), axis=-1)\n",
    "            \n",
    "            # Maximum of the sub band\n",
    "            sub_band_summerized = np.append(sub_band_summerized, np.amax(sub_band, axis=-1, keepdims=True), axis=-1)\n",
    "            \n",
    "            # Minimum of the sub band\n",
    "            sub_band_summerized = np.append(sub_band_summerized, np.amin(sub_band, axis=-1, keepdims=True), axis=-1)\n",
    "            \n",
    "            # Std of the sub band\n",
    "            sub_band_summerized = np.append(sub_band_summerized, np.std(sub_band, axis=-1, keepdims=True), axis=-1)\n",
    "            \n",
    "            # Variance of the sub band\n",
    "            sub_band_summerized = np.append(sub_band_summerized, np.var(sub_band, axis=-1, keepdims=True), axis=-1)\n",
    "            \n",
    "            # Range of the sub band\n",
    "            _range = np.ptp(sub_band, axis=-1)\n",
    "            _range = _range.reshape(exp,ch,1)\n",
    "            sub_band_summerized=np.append(sub_band_summerized, _range, axis=-1)\n",
    "            \n",
    "            # Skewness of the sub band\n",
    "            _skew = skew(sub_band, axis=-1)\n",
    "            _skew = _skew.reshape(exp,ch,1)\n",
    "            sub_band_summerized=np.append(sub_band_summerized, _range, axis=-1)\n",
    "            \n",
    "            # Kurtosis of the sub band\n",
    "            _kurtosis= kurtosis(sub_band, axis=-1)\n",
    "            _kurtosis = _kurtosis.reshape(exp,ch,1)\n",
    "            sub_band_summerized=np.append(sub_band_summerized, _range, axis=-1)\n",
    "            \"\"\"\n",
    "            return sub_band_summerized\n",
    "        \n",
    "        sub_band_list = []\n",
    "        # Theta band 4-7Hz\n",
    "        _, theta4 = periodogram(data, fs=4.0, window='hann', axis=-1)\n",
    "        _, theta5 = periodogram(data, fs=5.0, window='hann', axis=-1)\n",
    "        _, theta6 = periodogram(data, fs=6.0, window='hann', axis=-1)\n",
    "        _, theta7 = periodogram(data, fs=7.0, window='hann', axis=-1)\n",
    "        \n",
    "        sub_band_list.append(theta4)\n",
    "        sub_band_list.append(theta5)\n",
    "        sub_band_list.append(theta6)\n",
    "        sub_band_list.append(theta7)\n",
    "        \n",
    "        # Alpha band 8-12Hz\n",
    "        _, alpha8 = periodogram(data, fs=8.0, window='hann', axis=-1)\n",
    "        _, alpha9 = periodogram(data, fs=9.0, window='hann', axis=-1)\n",
    "        _, alpha11 = periodogram(data, fs=11.0, window='hann', axis=-1)\n",
    "        _, alpha12 = periodogram(data, fs=12.0, window='hann', axis=-1)\n",
    "        \n",
    "        \n",
    "        sub_band_list.append(alpha8)\n",
    "        sub_band_list.append(alpha9)\n",
    "        sub_band_list.append(alpha11)\n",
    "        sub_band_list.append(alpha12)\n",
    "        \n",
    "        # Lower Beta band 13-21Hz\n",
    "        _, lBetha13 = periodogram(data, fs=13.0, window='hann', axis=-1)\n",
    "        _, lBetha16 = periodogram(data, fs=16.0, window='hann', axis=-1)\n",
    "        _, lBetha19 = periodogram(data, fs=19.0, window='hann', axis=-1)\n",
    "        _, lBetha21 = periodogram(data, fs=21.0, window='hann', axis=-1)\n",
    "        \n",
    "        sub_band_list.append(lBetha13)\n",
    "        sub_band_list.append(lBetha16)\n",
    "        sub_band_list.append(lBetha19)\n",
    "        sub_band_list.append(lBetha21)\n",
    "        \n",
    "        \n",
    "        # Upper Beta band 22-30Hz\n",
    "        _, uBetha22 = periodogram(data, fs=22.0, window='hann', axis=-1)\n",
    "        _, uBetha24 = periodogram(data, fs=24.0, window='hann', axis=-1)\n",
    "        _, uBetha27 = periodogram(data, fs=27.0, window='hann', axis=-1)\n",
    "        _, uBetha30 = periodogram(data, fs=30.0, window='hann', axis=-1)\n",
    "        \n",
    "        sub_band_list.append(uBetha22)\n",
    "        sub_band_list.append(uBetha24)\n",
    "        sub_band_list.append(uBetha27)\n",
    "        sub_band_list.append(uBetha30)\n",
    "        \n",
    "        # Gamma band 30-45Hz\n",
    "        _, gamma32 = periodogram(data, fs=32.0, window='hann', axis=-1)\n",
    "        _, gamma37 = periodogram(data, fs=37.0, window='hann', axis=-1)\n",
    "        _, gamma41 = periodogram(data, fs=41.0, window='hann', axis=-1)\n",
    "        _, gamma45 = periodogram(data, fs=45.0, window='hann', axis=-1)\n",
    "        \n",
    "        sub_band_list.append(gamma32)\n",
    "        sub_band_list.append(gamma37)\n",
    "        sub_band_list.append(gamma41)\n",
    "        sub_band_list.append(gamma45)\n",
    "        \n",
    "        sub_band_list_summerized = []\n",
    "        for sub_band in sub_band_list:\n",
    "            sub_band_list_summerized.append(summerize(sub_band))\n",
    "        data_summerized = np.concatenate(sub_band_list_summerized, axis=-1)\n",
    "            \n",
    "        return data_summerized \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for data in my_egg_data:\n",
    "    train_data.append(psd(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 15, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('train_data.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('new_valence_folds.pickle', 'wb') as handle:\n",
    "    pickle.dump(new_valence_folds, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.models import load_model\n",
    "from keras import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "from keras.regularizers import l2\n",
    "import models.nnmodels as nn\n",
    "import utils.data as data\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "with open('train_data.pickle', 'rb') as handle:\n",
    "    train_data = pickle.load(handle)\n",
    "    \n",
    "with open('new_valence_folds.pickle', 'rb') as handle:\n",
    "    new_valence_folds = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "(400, 15, 20)\n",
      "(400, 2)\n"
     ]
    }
   ],
   "source": [
    "print len(train_data)\n",
    "print train_data[0].shape\n",
    "print new_valence_folds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_15ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 15, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.concatenate(train_data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06895836 -0.06895836 -0.06895836 -0.06895836 -0.06895836 -0.06895836\n",
      " -0.06895836 -0.06895836 -0.06895836 -0.06895836 -0.06895836 -0.06895836\n",
      " -0.06895836 -0.06895836 -0.06895836 -0.06895836 -0.06895836 -0.06895836\n",
      " -0.06895836 -0.06895836]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/venv2/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(12800, 15*20)\n",
    "X_norm = scale(X_train)\n",
    "\n",
    "X_norm = X_norm.reshape(12800, 15, 20)\n",
    "\n",
    "train_data = np.split(X_norm, 32)\n",
    "\n",
    "print train_data[0][365,14,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Two Classes Classification for Valence emotion Using Convolutional Neural Network #####\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_1/MaxPool' (op: 'MaxPool') with input shapes: [?,8,1,16].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-27c7013907c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_remaining_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCnnNew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/course_project/models/nnmodels.py\u001b[0m in \u001b[0;36mCnnNew\u001b[0;34m(num_classes, emotion, input_shape)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    488\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    489\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                                         data_format=self.data_format)\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    215\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[1;32m    216\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                           pool_mode='max')\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   3567\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[1;32m   3568\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3569\u001b[0;31m                            data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3570\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1956\u001b[0m                                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m                                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   1959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36m_max_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   2804\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   2805\u001b[0m         \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m         data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   2807\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/venv2/local/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_1/MaxPool' (op: 'MaxPool') with input shapes: [?,8,1,16]."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_subjects = 32\n",
    "batch_size = 50\n",
    "epochs = 250\n",
    "num_exp = 40\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "print '##### Two Classes Classification for Valence emotion Using Convolutional Neural Network #####\\n'\n",
    "\n",
    "num_subjects = 32\n",
    "\n",
    "for s in np.arange(0, num_subjects):\n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    X_val = reduced_data_folds[s]\n",
    "    X_val = np.expand_dims(X_val, axis=1)\n",
    "    y_val = valence_folds[s]\n",
    "    \n",
    "    X_remaining_folds = reduced_data_folds[:s]  + reduced_data_folds[s+1:]\n",
    "    y_remaining_folds = valence_folds[:s] + valence_folds[s+1:]\n",
    "    X_train = np.concatenate(X_remaining_folds)\n",
    "    X_train = np.expand_dims(X_train, axis=1)  \n",
    "    y_train = np.concatenate(y_remaining_folds)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    X_val = train_data[s]\n",
    "    X_val = np.expand_dims(X_val, axis=1)\n",
    "    y_val = new_valence_folds[s]\n",
    "    \n",
    "    X_remaining_folds = train_data[:s]  + train_data[s+1:]\n",
    "    y_remaining_folds = new_valence_folds[:s] + new_valence_folds[s+1:]\n",
    "    X_train = np.concatenate(X_remaining_folds)\n",
    "    X_train = np.expand_dims(X_train, axis=1)  \n",
    "    y_train = np.concatenate(y_remaining_folds)\n",
    "\n",
    "    model = nn.CnnNew(num_classes=2, emotion='valence', input_shape=X_train.shape[1:])\n",
    "\n",
    "\n",
    "\n",
    "    key = 's'+str(s+1).zfill(2)+'_valence(3classes)'\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# checkpoint\n",
    "    filepath=\"../saved_models/best_Cnn1D_model_for_{}.h5\".format(key)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy',\n",
    "                                verbose=1, save_best_only=True, mode='max', period=5)\n",
    "    \n",
    "    #tensorboard = TensorBoard(log_dir='../logs', histogram_freq=1, batch_size=50, write_graph=True, \\\n",
    "        #write_grads=True, write_images=True)\n",
    "    \n",
    "    callbacks_list = [checkpoint]#, tensorboard]    \n",
    "    \n",
    "       \n",
    "    hist = model.fit(X_train, y_train, \n",
    "             batch_size=batch_size,\n",
    "             epochs=epochs,\n",
    "             shuffle=True,\n",
    "             verbose=1,\n",
    "             validation_data=(X_val, y_val), callbacks=callbacks_list)\n",
    "\n",
    "    model.load_weights(filepath)\n",
    "    \n",
    "    #scores = model.evaluate(x=X_val, y=y_val)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val, batch_size=50)\n",
    "    \n",
    "    accuracy = np.sum(y_val_pred==y_val)/(2*len(y_val))\n",
    "\n",
    "    print '#### Result of CNN model for subject {} #####\\n'.format(str(s+1).zfill(2))\n",
    "    print \"Loss: {} , Accuracy : {}%\".format(scores[0], accuracy*100)\n",
    "    \n",
    "    print 'Training time: {}'.format(time.time() - start_time)\n",
    "\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(hist.history['categorical_accuracy'])\n",
    "    plt.plot(hist.history['val_categorical_accuracy'])\n",
    "    plt.title('Subject ' +str(s+1).zfill(2)+ ' CNN model accuracy for Valence')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('Subject ' +str(s+1).zfill(2)+ ' CNN model loss for Valence')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_acc_subject_idx, max_acc_subject_idx = np.argmin(accuracies), np.argmax(accuracies)\n",
    "\n",
    "avg_acc =  reduce(lambda x, y: x + y, accuracies) / len(accuracies)\n",
    "\n",
    "print 5*'#' + ' Accuracies per subject ' + 5*'#'\n",
    "\n",
    "print 'Subject {} has the minimum accuracy : {}%'.format(min_acc_subject_idx + 1, min(accuracies)*100)\n",
    "print 'Subject {} has the maximum accuracy : {}%'.format(max_acc_subject_idx + 1, max(accuracies)*100)\n",
    "print 'Average accuracy : {}%'.format(avg_acc*100)\n",
    "\n",
    "for subj in enumerate(accuracies):\n",
    "    print 'Accuracy of Subject {} : {}%'.format(subj[0]+1, subj[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
